{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from nltk.tokenize import WordPunctTokenizer        # splits all punctuations into separate tokens \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "word_punct_tokenizer = WordPunctTokenizer()\n",
    "\n",
    "def bow_movie_nltk(root,start,end):\n",
    "    # list of dict where each element of bow_per_movie is bow for that movie\n",
    "    bow_per_movie = [] \n",
    "    \n",
    "    for i in range(start,end):\n",
    "        bow = defaultdict(float)\n",
    "        string = \"\"\n",
    "        for j in range(1,len(root[i])):\n",
    "            string += root[i][j].text\n",
    "\n",
    "        tokens = word_punct_tokenizer.tokenize(string)\n",
    "        l_tokens = map(lambda t: t.lower(), tokens)\n",
    "        \n",
    "        ### Lemmatizing using wordnetlemmatizer\n",
    "        l_tokens = [wnl.lemmatize(i,j[0].lower()) if j[0].lower() in ['a','n','v'] else wnl.lemmatize(i) for i,j in pos_tag(l_tokens)]\n",
    "        \n",
    "        for token in l_tokens:\n",
    "            bow[token] += 1.0\n",
    "        bow_per_movie.append(bow)\n",
    "    return bow_per_movie\n",
    "\n",
    "## lemmatizing positive-negative words\n",
    "\n",
    "def pos_tagging_for_list(l):\n",
    "    new=[]\n",
    "    for i,j in pos_tag(l):\n",
    "        if j[0].lower() in ['a','n','v']:\n",
    "            new.append(wnl.lemmatize(i,j[0].lower()))\n",
    "        else:\n",
    "            new.append(wnl.lemmatize(i))\n",
    "    return set(new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import scipy\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "def train(train_x,train_y,test_x):\n",
    "    clf=DecisionTreeRegressor(max_depth=10)\n",
    "    clf.fit(train_x, train_y)\n",
    "    return clf.predict(test_x)\n",
    "\n",
    "def cal_mae(y_hat,y):\n",
    "    return np.mean(abs(y_hat-y))\n",
    "\n",
    "# Function that returns a list of target variables i.e. revenue for all movies in the given set(train/dev/test) of given file root\n",
    "def true_rev(start,end,root):\n",
    "    rev = []\n",
    "    for i in range(start,end):\n",
    "        rev.append(root[i][0].attrib['yvalue'])\n",
    "    rev=np.array(rev).astype(np.float)\n",
    "    return rev \n",
    "\n",
    "\n",
    "def mpl(train_x,train_y,test_x):\n",
    "    clf = MLPRegressor(hidden_layer_sizes=(300,300,300,300,300),alpha=0.01)\n",
    "    clf.fit(train_x, train_y) \n",
    "    return clf.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('dataset\\\\movies-data-v1.0\\\\movies-data-v1.0\\\\7domains-train-dev.tl.xml')\n",
    "root_traindev_to = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_per_movie_train = bow_movie_nltk(root_traindev_to,0,1147)\n",
    "bow_per_movie_dev=bow_movie_nltk(root_traindev_to,1147,1464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## uploading the positive/ negative words\n",
    "pos_list=open('positive-words.txt','r').readlines()\n",
    "neg_list=open('negative-words.txt','r').readlines()\n",
    "\n",
    "## refining it\n",
    "for i in range(len(pos_list)):\n",
    "    pos_list[i]=pos_list[i].replace('\\n','')\n",
    "    \n",
    "for i in range(len(neg_list)):\n",
    "    neg_list[i]=neg_list[i].replace('\\n','')\n",
    "    \n",
    "positive=[]\n",
    "negative=[]\n",
    "\n",
    "## lemmatizing it\n",
    "positive=pos_tagging_for_list(pos_list)\n",
    "negative=pos_tagging_for_list(neg_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## create the feature vector based on the absense and presence of pos-neg words\n",
    "\n",
    "feature=[]\n",
    "\n",
    "for bow in bow_per_movie_train:\n",
    "    feat=[]\n",
    "    for pos in positive:\n",
    "        if pos in bow.keys():\n",
    "            feat.append(1)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    for neg in negative:\n",
    "        if neg in bow.keys():\n",
    "            feat.append(-1)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "            \n",
    "    feature.append(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_dev=[]\n",
    "for bow in bow_per_movie_dev:\n",
    "    feat=[]\n",
    "    for pos in positive:\n",
    "        if pos in bow.keys():\n",
    "            feat.append(1)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "    for neg in negative:\n",
    "        if neg in bow.keys():\n",
    "            feat.append(-1)\n",
    "        else:\n",
    "            feat.append(0)\n",
    "            \n",
    "    feature_dev.append(feat)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('train_y_to.txt', 'r')\n",
    "train_y= pickle.load(f)\n",
    "\n",
    "f=open('dev_y_to.txt', 'r')\n",
    "test_y= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mpl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-45dd0d9410be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_hat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m\"MAE is \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcal_mae\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mpl' is not defined"
     ]
    }
   ],
   "source": [
    "y_hat=mpl(feature,train_y,feature_dev)\n",
    "print \"MAE is \", cal_mae(test_y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "f=open('train_pos_feat.txt', 'w')\n",
    "pickle.dump(feature,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f=open('dev_pos_feat.txt', 'w')\n",
    "pickle.dump(feature_dev,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
